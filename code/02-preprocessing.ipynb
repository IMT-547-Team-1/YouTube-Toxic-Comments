{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de6bcc0-6f0a-4ddb-ac55-8dc0044a50e9",
   "metadata": {},
   "source": [
    "# IMT 547 Project Part II: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f6709-61fb-40b7-8dfa-bdd7465b7b62",
   "metadata": {},
   "source": [
    "Chesie Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09122a0b-3052-44a0-ac0b-1f3066fb6fa0",
   "metadata": {},
   "source": [
    "02/18/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef03107-7f5a-4040-833b-d0be04112712",
   "metadata": {},
   "source": [
    "<style type = \"text/css\">  \n",
    "    body {\n",
    "        font-family: \"Serif\"; \n",
    "        font-size: 12pt;\n",
    "    }\n",
    "    em {\n",
    "        color: #4E7F9E;\n",
    "    }\n",
    "    strong {\n",
    "        color: #436D87;\n",
    "    }\n",
    "    li {\n",
    "        color: #4E7F9E;\n",
    "    }\n",
    "    ul {\n",
    "        color: #4E7F9E;\n",
    "    }\n",
    "    img {\n",
    "        display: block;\n",
    "        margin: auto;\n",
    "    } \n",
    "    .jp-RenderedHTMLCommon a:link { \n",
    "        color: #94C1C9;\n",
    "    }\n",
    "    .jp-RenderedHTMLCommon a:visited { \n",
    "        color: #94C1C9;\n",
    "    }\n",
    "    .jp-RenderedHTMLCommon code {\n",
    "        color: #4E7F9E;\n",
    "    }  \n",
    "    .mark {\n",
    "        color: #B00D00;\n",
    "        background-color: #FFF7B1;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7bc5b-28a2-4eeb-bca3-e2ece395e3c5",
   "metadata": {},
   "source": [
    "_This notebook outlines the **data preprocessing** process for the **YouTube Gaming Comment Toxicity** project._    \n",
    "\n",
    "**Components**  \n",
    "1. **Data Cleaning**: Data cleaning procedures including handling missing values and converting data types.    \n",
    "2. **Text Preprocessing**: Text cleaning measures including text standardization, irrelevant content removal, stopwords removal, and tokenization.   \n",
    "3. **Data Labeling**: Perspective API toxicity annotations and VADER/TextBlob/Empath sentiment scoring.  \n",
    "\n",
    "**Functions**   \n",
    "- **`clean(text)`**: Performs text preprocessing steps on a given document.  \n",
    "- **`build_client(api_key)`**: Build a client for a given Perspective API key.  \n",
    "- **`perspective_toxicity(comments)`**: Compute Perspective toxicity scores for a given list of texts. Support throttling management w/ client reuse, key rotation, and exponential backoff.   \n",
    "- **`vader_sentiment(text)`**: Compute VADER sentiment scores for a given text.    \n",
    "- **`textblob_sentiment(text)`**: Compute TextBlob sentiment scores for a given text.   \n",
    "- **`empath_sentiment(text)`**: Compute Empath sentiment scores for a given text.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1ac9b-3b43-478a-8780-d5438602df27",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578e3748-8eaf-4091-9fed-4ad15d858ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a0ad4-d252-402a-adb3-3fcd52f619da",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8f6b0-1b61-414c-ab0d-5692c4ed3019",
   "metadata": {},
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0545f22b-ffe1-44f0-b04b-50ab22781ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_creation_time</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>video_viewcount</th>\n",
       "      <th>video_likecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_author_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_time</th>\n",
       "      <th>comment_likecount</th>\n",
       "      <th>comment_replycount</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30T16:40:18Z</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>UgwN1kGXwi9M7jeOb0d4AaABAg</td>\n",
       "      <td>UCLHsZ4X7YemjxRrvq0AI4LA</td>\n",
       "      <td>Damn dude, even with mimic I think it would ta...</td>\n",
       "      <td>2022-05-02T19:37:22Z</td>\n",
       "      <td>9818.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30T16:40:18Z</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>UgwW5nWEkxdES-g3hk54AaABAg</td>\n",
       "      <td>UCJ9VDCLZDmeJIU3Branlstg</td>\n",
       "      <td>This is the pewds that I thought he‚Äôd turn int...</td>\n",
       "      <td>2022-12-14T23:36:11Z</td>\n",
       "      <td>6251.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id channel_name     video_id  \\\n",
       "0  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "1  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "\n",
       "                                         video_title   video_creation_time  \\\n",
       "0  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...  2022-04-30T16:40:18Z   \n",
       "1  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...  2022-04-30T16:40:18Z   \n",
       "\n",
       "                                   video_description  \\\n",
       "0  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "1  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "\n",
       "                         video_tags  video_viewcount  video_likecount  \\\n",
       "0  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "1  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "\n",
       "   video_commentcount                  comment_id         comment_author_id  \\\n",
       "0             15129.0  UgwN1kGXwi9M7jeOb0d4AaABAg  UCLHsZ4X7YemjxRrvq0AI4LA   \n",
       "1             15129.0  UgwW5nWEkxdES-g3hk54AaABAg  UCJ9VDCLZDmeJIU3Branlstg   \n",
       "\n",
       "                                        comment_text          comment_time  \\\n",
       "0  Damn dude, even with mimic I think it would ta...  2022-05-02T19:37:22Z   \n",
       "1  This is the pewds that I thought he‚Äôd turn int...  2022-12-14T23:36:11Z   \n",
       "\n",
       "   comment_likecount  comment_replycount   genre  \n",
       "0             9818.0                47.0  action  \n",
       "1             6251.0                 9.0  action  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "yt = pd.read_csv(\"../data/yt.csv\")\n",
    "yt.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af7613b-6557-4f34-82e0-93121776ddea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 140637\n",
      "Number of columns: 17\n",
      "\n",
      "Number of missing values: 877\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "print(f\"Number of rows: {yt.shape[0]}\\n\"\n",
    "      f\"Number of columns: {yt.shape[1]}\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"Number of missing values: {yt.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b5f9e8-c05a-401a-a295-2be3d887b12f",
   "metadata": {},
   "source": [
    "_The dataset contains **140,637 comments** collected from action and non-action gaming videos on YouTube.  It features **17 columns** on metadata associated with the videos and comments.  **877 missing entries** are detected in this dataset; in the subsequent sections, we will address these data quality concerns._    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d001c7-909b-473f-af1d-0fd62ccca873",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1203c-7d06-4dd9-993b-fb0270eb30d7",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f752f32-8d0a-45d4-98bb-bda10d1a6d4d",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35480390-3c96-48fb-aa1c-821861df3cb7",
   "metadata": {},
   "source": [
    "_Given that the missing entries account for only **0.624%** of the dataset, we will employ the **deletion** method to handle these missings.  By eliminitating rows that contain missing values, we ensure that our analysis is based on **complete and accurate** information._    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094f5778-c5fa-41d7-954a-a12e89b04eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_id               0\n",
       "channel_name             3\n",
       "video_id                 3\n",
       "video_title              3\n",
       "video_creation_time      3\n",
       "video_description      789\n",
       "video_tags               5\n",
       "video_viewcount          5\n",
       "video_likecount          5\n",
       "video_commentcount       5\n",
       "comment_id               5\n",
       "comment_author_id        5\n",
       "comment_text            18\n",
       "comment_time             7\n",
       "comment_likecount        7\n",
       "comment_replycount       7\n",
       "genre                    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missings\n",
    "yt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e8e076-3d37-4681-92da-f76fd5a9c9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139833, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the missings\n",
    "yt.dropna(inplace=True)\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfa059-4c07-4ec0-af3e-d554219fe207",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bc894-80b8-409b-a8e0-d540d506189c",
   "metadata": {},
   "source": [
    "### Convert Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3febc0-9106-4c83-a0b3-07d58fd6eee9",
   "metadata": {},
   "source": [
    "*Note that the **`video_creation_time`** and **`comment_time`** are represented as **objects**; since these two columns represent dates and times, we will convert them to the more appropriate type **`datetime`** for efficient anlaysis.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a229cc39-3531-4a90-b9d3-02a833676ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_id              object\n",
       "channel_name            object\n",
       "video_id                object\n",
       "video_title             object\n",
       "video_creation_time     object\n",
       "video_description       object\n",
       "video_tags              object\n",
       "video_viewcount        float64\n",
       "video_likecount        float64\n",
       "video_commentcount     float64\n",
       "comment_id              object\n",
       "comment_author_id       object\n",
       "comment_text            object\n",
       "comment_time            object\n",
       "comment_likecount      float64\n",
       "comment_replycount     float64\n",
       "genre                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types\n",
    "yt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2acffcb9-cf14-4591-9724-c2cb98b27e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "yt[\"video_creation_time\"] = pd.to_datetime(yt[\"video_creation_time\"])\n",
    "yt[\"comment_time\"] = pd.to_datetime(yt[\"comment_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e8d91-06ee-4f7c-9edd-f5d8cb51012f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af06563-26cf-45e8-847d-448b10e7483c",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f23384-ce74-4c00-a0e2-68f0d09657b7",
   "metadata": {},
   "source": [
    "### Filter English Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6bbf8-b72a-4a65-83f6-2cbba22ff998",
   "metadata": {},
   "source": [
    "_To **align** our analysis with the interests of the English-speaking YouTube gaming community, we intend to employ the **[spacy-langdetect](https://pypi.org/project/spacy-langdetect/)** tool to **filter our dataset for English comments** only.  However, our initial attempt to implement a code solution from SpaCy's documentation was unsuccessful; if time permits, we will explore alternative methods to isolate English comments for our analysis._    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b72ca2a-5306-4790-bb8d-cb41e435dd96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the SpaCy model\n",
    "# # Documentation: https://pypi.org/project/spacy-langdetect/\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n",
    "\n",
    "# def filter_english(comment):\n",
    "#     \"\"\"\n",
    "#     Detect English comments.  \n",
    "#     \"\"\"\n",
    "#     doc = nlp(comment)\n",
    "#     return doc._.languege[\"language\"] == \"en\" and doc._.language[\"score\"] > 0.95\n",
    "\n",
    "# yt = yt[yt[\"comment_text\"].apply(filter_english)]\n",
    "# yt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813571d0-a225-489e-a858-372910729925",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2220ed0-b688-4c35-ad83-7328291a1f8c",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4597de-23e4-4f0b-b006-9e20a21fdfc2",
   "metadata": {},
   "source": [
    "_To preserve the **most relevant information**, we will undertake a series of text preprocessing steps to refine our corpus for analysis._  \n",
    "\n",
    "_This initial step involves **text standardization** to ensure that the text will be **consistently understood** by analytical tools.  All texts will be converted to **lowercase**; **contractions** will be expanded to their full forms using the [`contractions`](https://pypi.org/project/contractions/) library._  \n",
    "\n",
    "_Next, we will **remove the URLs, mentions, hashtags, and non-alphabetic characters** to eliminate the noise in data.  Common English **stopwords** will also be removed as they do not possess significant information.  Note the **potential caveat** in this procedure: the elimination of these elements could result in loss of certain nuances in text._  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31039daa-0f8b-42bf-9a8c-765cbd9f9ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for text preprocessing\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Performs text preprocessing steps on a given document.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove contractions\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r\"(?<![@\\w])@(\\w{1,25})\", \"\", text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r\"(?<![#\\w])#(\\w{1,25})\", \"\", text)\n",
    "    # Remove new line characters\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591aa5a9-0e34-4e87-8083-19ce4367a262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Damn dude, even with mimic I think it would ta...\n",
       "1    This is the pewds that I thought he‚Äôd turn int...\n",
       "2    This is actually awesome. Can't believe a meme...\n",
       "3    Wow, didn't even know Pewds had this analytica...\n",
       "4    Damn, i cant believe it took me 11 months afte...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the comments\n",
    "comments = yt[\"comment_text\"]\n",
    "comments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2506d5a2-b7a3-4254-9690-6e6d29ad677f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean the comments\n",
    "comments = comments.apply(clean)\n",
    "\n",
    "# Remove empty comments\n",
    "comments = comments[comments.str.len() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1085b2-132b-455e-a9d1-98b06f9097bf",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e00bbd-5d61-452b-aa5b-206d6af40e37",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73dff0-cda3-4393-857a-e360074ea94d",
   "metadata": {},
   "source": [
    "*Using `word_tokenizer`, we will **tokenize** the text into smaller pieces.  This process will be crucial for **analyzing term frequency** or **identifying common themes** within the corpous as the analysis progresses.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25417b96-e261-402b-be72-a4c9b9ae794e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the comments\n",
    "tokenized_comments = comments.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be07c16d-816b-4a60-8d1c-bfa97aa457b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_creation_time</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>video_viewcount</th>\n",
       "      <th>video_likecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_author_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_time</th>\n",
       "      <th>comment_likecount</th>\n",
       "      <th>comment_replycount</th>\n",
       "      <th>genre</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>tokenized_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>UgwN1kGXwi9M7jeOb0d4AaABAg</td>\n",
       "      <td>UCLHsZ4X7YemjxRrvq0AI4LA</td>\n",
       "      <td>Damn dude, even with mimic I think it would ta...</td>\n",
       "      <td>2022-05-02 19:37:22+00:00</td>\n",
       "      <td>9818.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>action</td>\n",
       "      <td>damn dude even mimic think would take approxim...</td>\n",
       "      <td>[damn, dude, even, mimic, think, would, take, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>UgwW5nWEkxdES-g3hk54AaABAg</td>\n",
       "      <td>UCJ9VDCLZDmeJIU3Branlstg</td>\n",
       "      <td>This is the pewds that I thought he‚Äôd turn int...</td>\n",
       "      <td>2022-12-14 23:36:11+00:00</td>\n",
       "      <td>6251.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>action</td>\n",
       "      <td>pewds thought would turn gaming early channel ...</td>\n",
       "      <td>[pewds, thought, would, turn, gaming, early, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>UgyGe0HN8toQWUZZtCl4AaABAg</td>\n",
       "      <td>UCs-mo1206PASdacjDqfdLng</td>\n",
       "      <td>This is actually awesome. Can't believe a meme...</td>\n",
       "      <td>2022-12-31 18:16:36+00:00</td>\n",
       "      <td>5041.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>action</td>\n",
       "      <td>actually awesome cannot believe meme became tr...</td>\n",
       "      <td>[actually, awesome, can, not, believe, meme, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>UgynWxW3iPqZkLh107F4AaABAg</td>\n",
       "      <td>UCZbZYh7zCRnS1agWpUkOogw</td>\n",
       "      <td>Wow, didn't even know Pewds had this analytica...</td>\n",
       "      <td>2023-01-19 18:49:19+00:00</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>action</td>\n",
       "      <td>wow even know pewds analytical strategical gam...</td>\n",
       "      <td>[wow, even, know, pewds, analytical, strategic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>Ugw8ym0lRIWdoz5m8q14AaABAg</td>\n",
       "      <td>UCx2sOV-ra7OD75snrhwOWxA</td>\n",
       "      <td>Damn, i cant believe it took me 11 months afte...</td>\n",
       "      <td>2023-04-21 17:00:36+00:00</td>\n",
       "      <td>483.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>action</td>\n",
       "      <td>damn cannot believe took months finally watch ...</td>\n",
       "      <td>[damn, can, not, believe, took, months, finall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id channel_name     video_id  \\\n",
       "0  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "1  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "2  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "3  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "4  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "\n",
       "                                         video_title  \\\n",
       "0  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "1  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "2  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "3  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "4  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "\n",
       "        video_creation_time  \\\n",
       "0 2022-04-30 16:40:18+00:00   \n",
       "1 2022-04-30 16:40:18+00:00   \n",
       "2 2022-04-30 16:40:18+00:00   \n",
       "3 2022-04-30 16:40:18+00:00   \n",
       "4 2022-04-30 16:40:18+00:00   \n",
       "\n",
       "                                   video_description  \\\n",
       "0  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "1  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "2  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "3  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "4  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "\n",
       "                         video_tags  video_viewcount  video_likecount  \\\n",
       "0  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "1  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "2  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "3  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "4  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "\n",
       "   video_commentcount                  comment_id         comment_author_id  \\\n",
       "0             15129.0  UgwN1kGXwi9M7jeOb0d4AaABAg  UCLHsZ4X7YemjxRrvq0AI4LA   \n",
       "1             15129.0  UgwW5nWEkxdES-g3hk54AaABAg  UCJ9VDCLZDmeJIU3Branlstg   \n",
       "2             15129.0  UgyGe0HN8toQWUZZtCl4AaABAg  UCs-mo1206PASdacjDqfdLng   \n",
       "3             15129.0  UgynWxW3iPqZkLh107F4AaABAg  UCZbZYh7zCRnS1agWpUkOogw   \n",
       "4             15129.0  Ugw8ym0lRIWdoz5m8q14AaABAg  UCx2sOV-ra7OD75snrhwOWxA   \n",
       "\n",
       "                                        comment_text  \\\n",
       "0  Damn dude, even with mimic I think it would ta...   \n",
       "1  This is the pewds that I thought he‚Äôd turn int...   \n",
       "2  This is actually awesome. Can't believe a meme...   \n",
       "3  Wow, didn't even know Pewds had this analytica...   \n",
       "4  Damn, i cant believe it took me 11 months afte...   \n",
       "\n",
       "               comment_time  comment_likecount  comment_replycount   genre  \\\n",
       "0 2022-05-02 19:37:22+00:00             9818.0                47.0  action   \n",
       "1 2022-12-14 23:36:11+00:00             6251.0                 9.0  action   \n",
       "2 2022-12-31 18:16:36+00:00             5041.0                54.0  action   \n",
       "3 2023-01-19 18:49:19+00:00             1323.0                 2.0  action   \n",
       "4 2023-04-21 17:00:36+00:00              483.0                 3.0  action   \n",
       "\n",
       "                                     cleaned_comment  \\\n",
       "0  damn dude even mimic think would take approxim...   \n",
       "1  pewds thought would turn gaming early channel ...   \n",
       "2  actually awesome cannot believe meme became tr...   \n",
       "3  wow even know pewds analytical strategical gam...   \n",
       "4  damn cannot believe took months finally watch ...   \n",
       "\n",
       "                                   tokenized_comment  \n",
       "0  [damn, dude, even, mimic, think, would, take, ...  \n",
       "1  [pewds, thought, would, turn, gaming, early, c...  \n",
       "2  [actually, awesome, can, not, believe, meme, b...  \n",
       "3  [wow, even, know, pewds, analytical, strategic...  \n",
       "4  [damn, can, not, believe, took, months, finall...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into one DataFrame\n",
    "yt[\"cleaned_comment\"] = comments\n",
    "yt[\"tokenized_comment\"] = tokenized_comments\n",
    "yt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c7c456-f3b9-4f3a-b7b6-3e47776c4603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138996, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the missings\n",
    "yt.dropna(inplace=True)\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22a1a1a4-7746-46ec-bdad-ae02af2c89af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "yt.to_csv(\"../data/yt_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f0d86-17f1-4930-89d4-a476754578b7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825eaabb-d622-4f0b-8e74-ed0f1d80d5b0",
   "metadata": {},
   "source": [
    "## 4. Data Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828286e-d50b-482a-a229-6ce3117d9fe1",
   "metadata": {},
   "source": [
    "### Toxicity Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf9932-3172-460d-93e4-e7a6e95282c2",
   "metadata": {},
   "source": [
    "_Acquiring the toxicity labels is crucial for analyzing toxicity in comments.  However, manually annotating nearly 140,000 comments is **impractical** given the large volume and resource limitations.  Thus, to effectively **quantify the level of toxicity** in comments, we will leverage the **[Perspective API](https://perspectiveapi.com/)** to obtain our true labels._   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15930720-2cef-46db-b699-000a22c61c1e",
   "metadata": {},
   "source": [
    "**Quota Limits and Throttling Management**  \n",
    "\n",
    "*The Perspective API, however, enforces a **[quota limit](https://developers.perspectiveapi.com/s/about-the-api-limits-and-errors?language=en_US)** of **1 query per second (QPS)** for each project.  Despite the **lack of batch processing** support, we have devised a **throttling management** strategy that incorporates **key rotation** and **exponential backoff** to efficiently manage this constraint.*    \n",
    "\n",
    "_Our approach involves cycling through **10 different API keys** and their respective **pre-built clients**, enhancing our query capacity within the API's quota restrictions.  Furthermore, an **exponential backoff** mechanism is enforced to manage **retries** following any quota breaches or server errors.  This method will **systematically increase the delay between subsequent requests**, thereby minimizing the likelihood of succesive failures and mitigating the impact on the API server._  \n",
    "\n",
    "_Additional features such as **logging** and **exception handling** are integrated to support **monitoring** and **troubleshooting**, facilitating a smooth and efficient data lebeling process.  These measures collectively **reduce the projected processing time** from an initial estimate of **2.26 days** to approximately **4 hours**._    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9458940-51b6-46f3-85bc-19c3ca2e75ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import itertools\n",
    "import logging\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c175f3c1-9108-4d86-bff5-4abd2dc11157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The Perspective API keys\n",
    "PERSPECTIVE_API_KEYS = [\n",
    "    \"AIzaSyAMpL8JpwPU4c1nEGKCiBAiGp979r6o4-4\",  # perspective-api-414709\n",
    "    \"AIzaSyD_-Oiitvk4OL5zgvX90Nn5TcoA23TrMlM\",  # perspective-api-414723\n",
    "    \"AIzaSyCLQ0SAdw0-xKDEqGyTcBPO7yApPF2M3R0\",  # perspe-414800\n",
    "    \"AIzaSyDTzo_CBwQ_5zVDojWSBMnH1jI_F6rEs7s\",  # precise-antenna-414801\n",
    "    \"AIzaSyAt70Atcrnx2bfvFuPTwtvOV8Nf2PBPx4A\",  # sound-datum-414801\n",
    "    \"AIzaSyBgO09nuuysiO7YNqexVZiskWhJPSv5t3A\",  # perspective-api-414710\n",
    "    \"AIzaSyBFU4rFCLaCAVuQ0i4K3QhF_f9wBV4gBm4\",  # perspective-api-414800\n",
    "    \"AIzaSyC8kMo6iX7iXX_lj8gx8IM0LuNS8p94UA4\",  # shaped-canyon-414800\n",
    "    \"AIzaSyAhRHCYoYkRkQkco4NzhNuKT7Zm92BKOS8\",  # perspective-api-414801\n",
    "    \"AIzaSyCr_b9CLWmy9Rt0f0ME74ZZmh3uT6gAwpk\"  # hardy-order-414801\n",
    "]\n",
    "\n",
    "def build_client(api_key):\n",
    "    \"\"\"\n",
    "    Build a client for a given Perspective API key.\n",
    "    \"\"\"\n",
    "    # Create a client object\n",
    "    # Reference: https://developers.google.com/codelabs/setup-perspective-api#4\n",
    "    client = discovery.build(\n",
    "        \"commentanalyzer\",  # Name\n",
    "        \"vlalpha1\",  # Version\n",
    "        developerKey=api_key,\n",
    "        discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "        static_discovery=False\n",
    "    )\n",
    "    return client\n",
    "\n",
    "# Pre-build a client for each API key\n",
    "clients = {key: build_client(key) for key in PERSPECTIVE_API_KEYS}\n",
    "\n",
    "# Set up the iterator\n",
    "api_key_iterator = itertools.cycle(PERSPECTIVE_API_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e1aa43-cba7-4943-97f2-438b474a2ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure logging to file\n",
    "logging.basicConfig(\n",
    "    filename=\"../logs/toxicity.log\",\n",
    "    level=logging.INFO,  # Log info, warning, error, critical\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"w\"  # Overwrite on each run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42ad97bb-4e85-422a-adf4-3869cadf917f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perspective_toxicity(comments):\n",
    "    \"\"\"\n",
    "    Compute Perspective toxicity scores for a given list of texts.\n",
    "    Support throttling management w/ client reuse, key rotation, and \n",
    "    exponential backoff.\n",
    "    \"\"\"\n",
    "    # Empty list to store toxicity scores\n",
    "    scores = []\n",
    "\n",
    "    # Loop through the comments\n",
    "    for index, comment in enumerate(comments):\n",
    "        # Specify the comment text and attributes\n",
    "        analyze_request = {\n",
    "            \"comment\": {\"text\": comment},\n",
    "            \"languages\": [\"en\"],\n",
    "            \"requestedAttributes\": {\n",
    "                \"TOXICITY\": {},\n",
    "                \"SEVERE_TOXICITY\": {},\n",
    "                \"IDENTITY_ATTACK\": {},\n",
    "                \"INSULT\": {},\n",
    "                \"PROFANITY\": {},\n",
    "                \"THREAT\": {}}\n",
    "        }\n",
    "        \n",
    "        # Attempts allowed\n",
    "        attempts_per_key = 5\n",
    "        total_attempts = len(PERSPECTIVE_API_KEYS) * attempts_per_key\n",
    "        # Reset attempt count for each comment\n",
    "        attempt = 0\n",
    "        \n",
    "        # While retry attempts are not exhausted\n",
    "        while attempt < total_attempts:\n",
    "            # Rotate to the next API key\n",
    "            current_key = next(api_key_iterator)\n",
    "            client = clients[current_key]\n",
    "        \n",
    "            try:\n",
    "                res = client.comments().analyze(body=analyze_request).execute()\n",
    "                scores.append({\n",
    "                    \"toxicity\": res[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"],\n",
    "                    \"severe_toxicity\": res[\"attributeScores\"][\"SEVERE_TOXICITY\"][\"summaryScore\"][\"value\"],\n",
    "                    \"identity_attack\": res[\"attributeScores\"][\"IDENTITY_ATTACK\"][\"summaryScore\"][\"value\"],\n",
    "                    \"insult\": res[\"attributeScores\"][\"INSULT\"][\"summaryScore\"][\"value\"],\n",
    "                    \"profanity\": res[\"attributeScores\"][\"PROFANITY\"][\"summaryScore\"][\"value\"],\n",
    "                    \"threat\": res[\"attributeScores\"][\"THREAT\"][\"summaryScore\"][\"value\"]\n",
    "                })\n",
    "                logging.info(f\"Success for comment #{index} with key {current_key} on attempt {attempt + 1}\")\n",
    "                # Break the loop if successful\n",
    "                break\n",
    "            \n",
    "            # Http errors\n",
    "            except HttpError as e:\n",
    "                # Rate limit errors\n",
    "                if e.resp.status == 429:\n",
    "                    logging.warning(f\"HTTP 429 Rate limit exceeded for comment #{index} with key '{current_key}' on attempt {attempt + 1}. Retrying with exponential backoff.\")\n",
    "                else:\n",
    "                    logging.warning(f\"HTTP error for comment #{index} with key '{current_key}' on attempt {attempt + 1}: {e}. Retrying with exponential backoff.\")\n",
    "            # Timeout errors\n",
    "            except TimeoutError:\n",
    "                logging.warning(f\"TimeoutError for comment #{index} with key '{current_key}' on attempt {attempt + 1}. Retrying with exponential backoff.\")\n",
    "            # Unexpected errors\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Unexpected error for comment #{index} with key '{current_key}' on attempt {attempt + 1}: {e}. Retrying with exponential backoff.\")\n",
    "            \n",
    "            # Exponential backoff + random jitter\n",
    "            sleep_time = (2 ** (attempt // len(PERSPECTIVE_API_KEYS))) + random.uniform(0, 1)\n",
    "            time.sleep(sleep_time)\n",
    "            attempt += 1\n",
    "            \n",
    "            # Check if all retry attempts are exhausted\n",
    "            if attempt >= total_attempts:\n",
    "                logging.error(f\"Max attempts reached for comment #{index} with key {current_key}. Moving to the next comment.\")\n",
    "\n",
    "        # Sleep to avoid exceeding rate limits\n",
    "        # time.sleep(0.05)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    toxicity_scores = pd.DataFrame(scores)\n",
    "    \n",
    "    return toxicity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71bad2ec-9bec-40ec-9332-ec89a3cef0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 14948.2070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>profanity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.642621</td>\n",
       "      <td>0.169603</td>\n",
       "      <td>0.044097</td>\n",
       "      <td>0.342037</td>\n",
       "      <td>0.600193</td>\n",
       "      <td>0.138155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093515</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.023351</td>\n",
       "      <td>0.038906</td>\n",
       "      <td>0.009515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.201028</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>0.098687</td>\n",
       "      <td>0.106963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.137353</td>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.028061</td>\n",
       "      <td>0.060951</td>\n",
       "      <td>0.013217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509388</td>\n",
       "      <td>0.120196</td>\n",
       "      <td>0.034301</td>\n",
       "      <td>0.249039</td>\n",
       "      <td>0.498944</td>\n",
       "      <td>0.014566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxicity  severe_toxicity  identity_attack    insult  profanity    threat\n",
       "0  0.642621         0.169603         0.044097  0.342037   0.600193  0.138155\n",
       "1  0.093515         0.004025         0.012943  0.023351   0.038906  0.009515\n",
       "2  0.201028         0.011749         0.016059  0.025929   0.098687  0.106963\n",
       "3  0.137353         0.007057         0.013345  0.028061   0.060951  0.013217\n",
       "4  0.509388         0.120196         0.034301  0.249039   0.498944  0.014566"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit -r 1 -n 3\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Compute Perspective API toxicity scores for each comment\n",
    "toxicity_scores = perspective_toxicity(comments)\n",
    "\n",
    "# End timing\n",
    "print(f\"Runtime: {time.time() - start_time:.4f}\")\n",
    "toxicity_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e608dd4a-149e-4b8d-9f89-65639ba9577e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_creation_time</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>video_viewcount</th>\n",
       "      <th>video_likecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_replycount</th>\n",
       "      <th>genre</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>profanity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>action</td>\n",
       "      <td>damn dude even mimic think would take approxim...</td>\n",
       "      <td>[damn, dude, even, mimic, think, would, take, ...</td>\n",
       "      <td>0.642621</td>\n",
       "      <td>0.169603</td>\n",
       "      <td>0.044097</td>\n",
       "      <td>0.342037</td>\n",
       "      <td>0.600193</td>\n",
       "      <td>0.138155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>action</td>\n",
       "      <td>pewds thought would turn gaming early channel ...</td>\n",
       "      <td>[pewds, thought, would, turn, gaming, early, c...</td>\n",
       "      <td>0.093515</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.023351</td>\n",
       "      <td>0.038906</td>\n",
       "      <td>0.009515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>action</td>\n",
       "      <td>actually awesome cannot believe meme became tr...</td>\n",
       "      <td>[actually, awesome, can, not, believe, meme, b...</td>\n",
       "      <td>0.201028</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>0.098687</td>\n",
       "      <td>0.106963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>action</td>\n",
       "      <td>wow even know pewds analytical strategical gam...</td>\n",
       "      <td>[wow, even, know, pewds, analytical, strategic...</td>\n",
       "      <td>0.137353</td>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.028061</td>\n",
       "      <td>0.060951</td>\n",
       "      <td>0.013217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>action</td>\n",
       "      <td>damn cannot believe took months finally watch ...</td>\n",
       "      <td>[damn, can, not, believe, took, months, finall...</td>\n",
       "      <td>0.509388</td>\n",
       "      <td>0.120196</td>\n",
       "      <td>0.034301</td>\n",
       "      <td>0.249039</td>\n",
       "      <td>0.498944</td>\n",
       "      <td>0.014566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id channel_name     video_id  \\\n",
       "0  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "1  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "2  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "3  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "4  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "\n",
       "                                         video_title  \\\n",
       "0  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "1  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "2  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "3  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "4  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "\n",
       "        video_creation_time  \\\n",
       "0 2022-04-30 16:40:18+00:00   \n",
       "1 2022-04-30 16:40:18+00:00   \n",
       "2 2022-04-30 16:40:18+00:00   \n",
       "3 2022-04-30 16:40:18+00:00   \n",
       "4 2022-04-30 16:40:18+00:00   \n",
       "\n",
       "                                   video_description  \\\n",
       "0  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "1  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "2  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "3  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "4  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "\n",
       "                         video_tags  video_viewcount  video_likecount  \\\n",
       "0  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "1  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "2  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "3  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "4  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "\n",
       "   video_commentcount  ... comment_replycount   genre  \\\n",
       "0             15129.0  ...               47.0  action   \n",
       "1             15129.0  ...                9.0  action   \n",
       "2             15129.0  ...               54.0  action   \n",
       "3             15129.0  ...                2.0  action   \n",
       "4             15129.0  ...                3.0  action   \n",
       "\n",
       "                                     cleaned_comment  \\\n",
       "0  damn dude even mimic think would take approxim...   \n",
       "1  pewds thought would turn gaming early channel ...   \n",
       "2  actually awesome cannot believe meme became tr...   \n",
       "3  wow even know pewds analytical strategical gam...   \n",
       "4  damn cannot believe took months finally watch ...   \n",
       "\n",
       "                                   tokenized_comment  toxicity  \\\n",
       "0  [damn, dude, even, mimic, think, would, take, ...  0.642621   \n",
       "1  [pewds, thought, would, turn, gaming, early, c...  0.093515   \n",
       "2  [actually, awesome, can, not, believe, meme, b...  0.201028   \n",
       "3  [wow, even, know, pewds, analytical, strategic...  0.137353   \n",
       "4  [damn, can, not, believe, took, months, finall...  0.509388   \n",
       "\n",
       "   severe_toxicity identity_attack    insult profanity    threat  \n",
       "0         0.169603        0.044097  0.342037  0.600193  0.138155  \n",
       "1         0.004025        0.012943  0.023351  0.038906  0.009515  \n",
       "2         0.011749        0.016059  0.025929  0.098687  0.106963  \n",
       "3         0.007057        0.013345  0.028061  0.060951  0.013217  \n",
       "4         0.120196        0.034301  0.249039  0.498944  0.014566  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into one DataFrame\n",
    "for column in toxicity_scores.columns:\n",
    "    yt[column] = toxicity_scores[column].values\n",
    "yt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f486efcd-6428-4d5d-9abd-a7fdd81f3dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138996, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db0d885e-d2bb-468c-9383-c6b53a80db63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # The URL for the Perspective API\n",
    "# url = \"https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=\" + PERSPECTIVE_API_KEY\n",
    "\n",
    "# # The data sent to request\n",
    "# data_dict = {\n",
    "#     \"comment\": {\"text\": \"Friendly discussion is cool, but please no personal attacks!\"},\n",
    "#     \"languages\": [\"en\"],\n",
    "#     \"requestedAttributes\": {\"TOXICITY\": {}}\n",
    "# }\n",
    "\n",
    "# response = requests.post(url, data=json.dumps(data_dict))\n",
    "# result = response.json()\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff02a1-063d-4255-8d80-979354ee7b41",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1c3a3-2632-4fc3-9c69-65a544130c5e",
   "metadata": {},
   "source": [
    "### Sentiment Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402449d-082c-4371-b4d4-5a7778e4bd20",
   "metadata": {},
   "source": [
    "_To further investigate the **emotional dynamics** of the comments, we will generate the **sentiment scores** using **VADER**, **TextBlob**, and **Empath**.  Note that our initial analysis with Empath will concentrate on positive and negative emotions; yet if time allows, we hope to extend our examination to encompass all Empath categories in the future, aiming for a more nuanced understanding of the prevalent themes within YouTube gaming comments._  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a879bc68-42e9-4bd5-9327-4383e4efd620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from empath import Empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc1de1ed-c6cb-4168-9328-8aeaa47750fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vader_sentiment(text):\n",
    "    \"\"\"\n",
    "    Compute VADER sentiment scores for a given text.\n",
    "    \"\"\"\n",
    "    # Initialize the analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Compute the scores\n",
    "    return analyzer.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a75507c-7695-43f2-b548-d7a02f81a24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.7906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.9324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.5709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.315  0.572  0.113   -0.6395\n",
       "1  0.000  0.703  0.297    0.5859\n",
       "2  0.124  0.442  0.434    0.7906\n",
       "3  0.000  0.549  0.451    0.9324\n",
       "4  0.093  0.687  0.220    0.5709"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "# Compute VADER sentiment scores for each comment\n",
    "vader_scores = comments.apply(vader_sentiment).apply(pd.Series)\n",
    "vader_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17b84010-1737-4e68-a0f3-48521422a247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def textblob_sentiment(text):\n",
    "    \"\"\"\n",
    "    Compute TextBlob sentiment scores for a given text.\n",
    "    \"\"\"\n",
    "    # Initialize the analyzer\n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    # Compute the scores\n",
    "    return {\"polarity\": blob.sentiment.subjectivity, \n",
    "            \"subjectivity\": blob.sentiment.subjectivity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce948693-e02d-4a3f-8b3c-a37bd396be5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.345238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  subjectivity\n",
       "0  0.400000      0.400000\n",
       "1  0.345238      0.345238\n",
       "2  0.583333      0.583333\n",
       "3  0.560000      0.560000\n",
       "4  0.675000      0.675000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute TextBlob sentiment scores for each comment\n",
    "textblob_scores = comments.apply(textblob_sentiment).apply(pd.Series)\n",
    "textblob_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90d0d6a9-8b3f-478c-bfcf-0197b70dc120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def empath_sentiment(text):\n",
    "    \"\"\"\n",
    "    Compute Empath sentiment scores for a given text.\n",
    "    \"\"\"\n",
    "    # Initialize the analyzer\n",
    "    lexicon = Empath()\n",
    "    \n",
    "    # Compute the scores\n",
    "    categories = lexicon.analyze(text, normalize=True)\n",
    "    \n",
    "    # Filter out the positive and negative emotions\n",
    "    return {k:v for k, v in categories.items() if k in [\"positive_emotion\", \"negative_emotion\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e44e8d9b-05d1-4794-914c-2534c9f6f92c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_emotion</th>\n",
       "      <th>positive_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negative_emotion  positive_emotion\n",
       "0          0.066667          0.000000\n",
       "1          0.000000          0.100000\n",
       "2          0.071429          0.000000\n",
       "3          0.000000          0.000000\n",
       "4          0.000000          0.043478"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Empath sentiment scores for each comment\n",
    "empath_scores = comments.apply(empath_sentiment).apply(pd.Series)\n",
    "empath_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b110caeb-9a8a-499c-bb57-ddab26b968c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_creation_time</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>video_viewcount</th>\n",
       "      <th>video_likecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>...</th>\n",
       "      <th>profanity</th>\n",
       "      <th>threat</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>negative_emotion</th>\n",
       "      <th>positive_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600193</td>\n",
       "      <td>0.138155</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.6395</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038906</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098687</td>\n",
       "      <td>0.106963</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060951</td>\n",
       "      <td>0.013217</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>F-yEoHL7MYY</td>\n",
       "      <td>I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...</td>\n",
       "      <td>2022-04-30 16:40:18+00:00</td>\n",
       "      <td>üåè Get exclusive NordVPN deal here ‚ûµ  https://N...</td>\n",
       "      <td>['pewdiepie', 'pewds', 'pewdie']</td>\n",
       "      <td>11540558.0</td>\n",
       "      <td>473052.0</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498944</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id channel_name     video_id  \\\n",
       "0  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "1  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "2  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "3  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "4  UC-lHJZR3Gqxm24_Vd_AJ5Yw    PewDiePie  F-yEoHL7MYY   \n",
       "\n",
       "                                         video_title  \\\n",
       "0  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "1  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "2  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "3  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "4  I tÃ∂rÃ∂iÃ∂eÃ∂dÃ∂ Ã∂tÃ∂oÃ∂ beat Elden Ring Without Dyi...   \n",
       "\n",
       "        video_creation_time  \\\n",
       "0 2022-04-30 16:40:18+00:00   \n",
       "1 2022-04-30 16:40:18+00:00   \n",
       "2 2022-04-30 16:40:18+00:00   \n",
       "3 2022-04-30 16:40:18+00:00   \n",
       "4 2022-04-30 16:40:18+00:00   \n",
       "\n",
       "                                   video_description  \\\n",
       "0  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "1  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "2  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "3  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "4  üåè Get exclusive NordVPN deal here ‚ûµ  https://N...   \n",
       "\n",
       "                         video_tags  video_viewcount  video_likecount  \\\n",
       "0  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "1  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "2  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "3  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "4  ['pewdiepie', 'pewds', 'pewdie']       11540558.0         473052.0   \n",
       "\n",
       "   video_commentcount  ... profanity    threat    neg    neu    pos  compound  \\\n",
       "0             15129.0  ...  0.600193  0.138155  0.315  0.572  0.113   -0.6395   \n",
       "1             15129.0  ...  0.038906  0.009515  0.000  0.703  0.297    0.5859   \n",
       "2             15129.0  ...  0.098687  0.106963  0.124  0.442  0.434    0.7906   \n",
       "3             15129.0  ...  0.060951  0.013217  0.000  0.549  0.451    0.9324   \n",
       "4             15129.0  ...  0.498944  0.014566  0.093  0.687  0.220    0.5709   \n",
       "\n",
       "   polarity subjectivity negative_emotion  positive_emotion  \n",
       "0  0.400000     0.400000         0.066667          0.000000  \n",
       "1  0.345238     0.345238         0.000000          0.100000  \n",
       "2  0.583333     0.583333         0.071429          0.000000  \n",
       "3  0.560000     0.560000         0.000000          0.000000  \n",
       "4  0.675000     0.675000         0.000000          0.043478  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into one DataFrame\n",
    "yt = pd.concat([yt, vader_scores, textblob_scores, empath_scores], axis=1)\n",
    "yt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7496edc9-b26b-4e3f-b67e-71e281095267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138996, 33)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e69cc16c-3be5-40d4-a690-b5b2675b7887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "yt.to_csv(\"../data/yt_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48462fee-03dd-4282-b9cb-621e5d62b4dd",
   "metadata": {},
   "source": [
    "_The labeled dataset contains **138,996 rows** and **33 columns**.  In `03-preliminary anlaysis`, we will begin to explore the dataset, examining its **distribution** through **exploratory data analysis** and **visualizations**._   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
